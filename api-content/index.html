{"posts":[{"title":"Spring 注解详解","content":"ControllerAdvice 全局异常处理@ControllerAdvice public class MyGlobalExceptionHandler { @ExceptionHandler(Exception.class) @ResponseBody String handleException(Exception e){ return &quot;handler exception： &quot; + e.getMessage(); } } 2. 全局数据绑定 ```java @ControllerAdvice public class MyGlobalExceptionHandler { @ModelAttribute(name = &quot;md&quot;) public Map&lt;String,Object&gt; mydata() { HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;age&quot;, 99); map.put(&quot;gender&quot;, &quot;男&quot;); return map; } } 所有Controller中都可以获取到数据 @RestController public class HelloController { @GetMapping(&quot;/hello&quot;) public String hello(Model model) { Map&lt;String, Object&gt; map = model.asMap(); System.out.println(map); int i = 1 / 0; return &quot;hello controller advice&quot;; } } 全局数据预处理 ","link":"https://maodou38.github.io/spring-zhu-jie-xiang-jie/"},{"title":"Nginx使用","content":"Nginx作为缓存使用 proxy_cache_path 语法：proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]。 只能用在http中。 proxy_cache_path /root/cache levels=1:2 keys_zone=zzm_cache:10m max_size=1g inactive=60m use_temp_path=off; 缓存管理器会定时检查缓存的状态。如果缓存的内容大小达到了指令proxy_cache_path的参数max-size指定的值,则缓存管理器会根据LRU算法删除缓存的内容。 在检查的间隔时间内，总的缓存内容大小可以临时超过设定的大小阈值。 缓存加载器只在Nginx启动的时候执行一次，将缓存内容的原信息加载到指定的共享内存区内。一次将所有的缓存内容加载到内存中会耗费大量的资源，并且会影响Nginx启动后几分钟内的性能。为了避免这种问题可以通过在指令proxy_cache_path后添加下面的参数： ● loader_threshold – 缓存加载器加载缓存内容的最大执行时间（单位是毫秒，默认值是200毫秒） ● loader_files – 在缓存加载器加载缓存内容的执行时间间隔内，最多能加载多少个缓存条目，默认100。 ● loader_sleeps – 每两次执行的时间间隔, 单位是毫秒 (默认50毫秒) ● purger=on 是否启动purge进程 proxy_cache_path /data/nginx/cache keys_zone=one:10m loader_threshold=300 loader_files=200; /root/cache：定义 proxy_cache 生成文件的根路径 levels：默认所有缓存文件都放在上面指定的根路径中，从而可能影响缓存的性能。推荐指定为 2 级目录来存储缓存文件 key_zone：这个的值是字符串，可以随意写。用于在共享内存中定义一块存储区域来存放缓存的 key 和 metadata（类似于使用次数），这样 nginx 可以快速判断一个 request 是否命中缓存。1m 可以存储 8000 个key,10m可以存在80000个key max_size：最大 cache 空间。如果不指定，会使用掉所有 disk space。当达到 disk 上限后，会删除最少使用的 cache inactive：内存中缓存的过期检查周期。示例配置中如果 1h 内都没有被访问，则不论状态是否为 expired，都会清除缓存。需要注意的是，inactive 和 expired 配置项的含义是不同的，expired 只是判断过期时间，不会删除缓存；而 inactive 是直接删除过期缓存 use_temp_path：如果为 off，则 nginx 会将缓存文件直接写入指定的 cache 文件中，而不使用 temp_path 指定的临时存储路径 proxy_cache proxy_cache zone | off。默认是关闭的，可以用在http,server,location中。 location / { proxy_cache zzm_cache; proxy_pass http://zzm; proxy_cache_valid 200 304 12h; proxy_cache_valid any 10m; proxy_cache_key $host$uri$is_args$args; add_header Nginx-Cache &quot;$upstream_cache_status&quot;; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; } proxy_cache：对应 http 段的 key_zone，是你定义的 proxy_cache 所使用的共享空间的名称，我在1.1中定义的是zzm_cache，所以在这里也写的是zzm_cache。 proxy_cache_key 控制缓存KEY的生成规则 proxy_cache_key &quot;$host$request_uri$cookie_user&quot;; proxy_cache_min_uses 指定一个请求的响应被缓存前的最小访问次数 proxy_cache_min_uses 5; proxy_cache_methods 指定只有哪些HTTP请求类型才能被缓存 proxy_cache_methods GET HEAD POST; proxy_cache_valid：对指定的 HTTP 状态进行缓存，并指定缓存时间。可以自定义写入多个配置项。这里我们对200和304的返回码缓存12小时。其余的缓存10分钟 proxy_cache_valid 200 302 10m; proxy_cache_valid 404 1m; proxy_cache_valid any 5m; proxy_cache_bypass 指定Nginx使用缓存的条件 #该指令的每个参数都指定了一个条件，只有请求满足其中的任何一个条件，并且参数的值不是0，则Nginx会把请求转发到后端的服务而不会使用缓存。 proxy_cache_bypass $cookie_nocache $arg_nocache$arg_comment; proxy_no_cache 指定哪些请求不需要Nginx来缓存 proxy_no_cache $http_pragma $http_authorization; is_args:如果$args设置，值为&quot;?&quot;，否则为&quot;&quot; proxy_next_upstream 当请求服务器发生错误或超时时，会尝试到下一台服务器 缓存扩展 rm 缓存目录所有文件 使用ngx_cache_purge location ~ /purge(/.*) { allow all; #127.0.0.1; 只允许本机访问 deny all; #禁止其他所有ip proxy_cache_purge cache_one $host$1$is_args$args; #清理缓存 access_log logs/cache.log cache; # 增加清理输出日志 } http { ... proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=mycache:10m purger=on; map $request_method $purge_method { PURGE 1; default 0; } server { listen 80; server_name www.example.com; location / { proxy_pass https://localhost:8002; proxy_cache mycache; proxy_cache_purge $purge_method; } } geo $purge_allowed { default 0; 10.0.0.1 1; 192.168.0.0/24 1; } map $request_method $purge_method { PURGE $purge_allowed; default 0; } } 部分页面不缓存 缓存命中分析 通过设置response的头信息Nginx-Cache add_header Nging-Cache &quot;$upstream_cache_status&quot;; 通过设置log_format,打印日志分析 示例 user www; worker_processes 8; events { worker_connections 65535; } http { include mime.types; default_type application/octet-stream; charset utf-8; log_format main '$http_x_forwarded_for $remote_addr $remote_user [$time_local] &quot;$request&quot; ' '$status $body_bytes_sent &quot;$http_referer&quot; ' '&quot;$http_user_agent&quot; &quot;$http_cookie&quot; $host $request_time'; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; #要想开启nginx的缓存功能，需要添加此处的两行内容！ #设置Web缓存区名称为cache_one,内存缓存空间大小为500M,缓存的数据超过1天没有被访问就自动清除;访问的缓存数据,硬盘缓存空间大小为30G proxy_cache_path /usr/local/nginx/proxy_cache_path levels=1:2 keys_zone=cache_one:500m inactive=1d max_size=30g; #创建缓存的时候可能生成一些临时文件存放的位置 proxy_temp_path /usr/local/nginx/proxy_temp_path; fastcgi_connect_timeout 3000; fastcgi_send_timeout 3000; fastcgi_read_timeout 3000; fastcgi_buffer_size 256k; fastcgi_buffers 8 256k; fastcgi_busy_buffers_size 256k; fastcgi_temp_file_write_size 256k; fastcgi_intercept_errors on; client_header_timeout 600s; client_body_timeout 600s; client_max_body_size 100m; client_body_buffer_size 256k; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.1; gzip_comp_level 9; gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/x-httpd-php; gzip_vary on; include vhosts/*.conf; } ","link":"https://maodou38.github.io/nginx/"},{"title":"Validation使用","content":"原生支持 全局校验处理 demo @Data public class TableBO { @NotBlank private String id; @NotBlank private String data; } 添加@Validated注解 @PutMapping(value = &quot;/updateById&quot;, consumes = MediaType.APPLICATION_JSON_UTF8_VALUE) public ResultVO updateTableDataById(@Validated @RequestBody TableBO tableBO) { return standBookService.modifyCellData(tableBO); } 编写一个全局异常类，并拦截MethodArgumentNotValidException异常 @RestControllerAdvice public class GlobalExceptionHandler { @ExceptionHandler(MethodArgumentNotValidException.class) public ResultVO handleMethodArgumentNotValidException(MethodArgumentNotValidException e){ BindingResult bindingResult = e.getBindingResult(); StringBuilder sb = new StringBuilder(&quot;校验失败:&quot;); for (FieldError fieldError : bindingResult.getFieldErrors()) { sb.append(fieldError.getField() + &quot;：&quot; + fieldError.getDefaultMessage() + &quot;, &quot;); } return ResultVOUtils.error(ResultEnum.PARAM_ERROR.getCode(), sb.toString()); } } 分组校验demo Class Foo{ @Min(value = 18,groups = {Adult.class}) private Integer age; public interface Adult{} } 只有Adult分组下会校验 @RequestMapping(&quot;/drink&quot;) public String drink(@Validated({Foo.Adult.class}) Foo foo, BindingResult bindingResult) { if(bindingResult.hasErrors()){ for (FieldError fieldError : bindingResult.getFieldErrors()) { //... } return &quot;fail&quot;; } return &quot;success&quot;; } @RequestMapping(&quot;/live&quot;) public String live(@Validated Foo foo, BindingResult bindingResult) { if(bindingResult.hasErrors()){ for (FieldError fieldError : bindingResult.getFieldErrors()) { //... } return &quot;fail&quot;; } return &quot;success&quot;; } 自定义校验注解demo @Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER}) @Retention(RUNTIME) @Documented @Constraint(validatedBy = {CannotHaveBlankValidator.class})&lt;1&gt; public @interface CannotHaveBlank { //默认错误消息 String message() default &quot;不能包含空格&quot;; //分组 Class&lt;?&gt;[] groups() default {}; //负载 Class&lt;? extends Payload&gt;[] payload() default {}; //指定多个时使用 @Target({FIELD, METHOD, PARAMETER, ANNOTATION_TYPE}) @Retention(RUNTIME) @Documented @interface List { CannotHaveBlank[] value(); } } 校验类 public class CannotHaveBlankValidator implements ConstraintValidator&lt;CannotHaveBlank, String&gt; { @Override public void initialize(CannotHaveBlank constraintAnnotation) { } @Override public boolean isValid(String value, ConstraintValidatorContext context ) { //null时不进行校验 if (value != null &amp;&amp; value.contains(&quot; &quot;)) { //获取默认提示信息 String defaultConstraintMessageTemplate = context.getDefaultConstraintMessageTemplate(); System.out.println(&quot;default message :&quot; + defaultConstraintMessageTemplate); //禁用默认提示信息 context.disableDefaultConstraintViolation(); //设置提示语 context.buildConstraintViolationWithTemplate(&quot;can not contains blank&quot;).addConstraintViolation(); return false; } return true; } } 基于方法校验 @RestController @Validated &lt;1&gt; public class BarController { @RequestMapping(&quot;/bar&quot;) public &lt;2.1&gt; @NotBlank String (@Min(18) Integer age &lt;2.2&gt;) { System.out.println(&quot;age : &quot; + age); return &quot;&quot;; } @ExceptionHandler(ConstraintViolationException.class) public Map handleConstraintViolationException(ConstraintViolationException cve){ Set&lt;ConstraintViolation&lt;?&gt;&gt; cves = cve.getConstraintViolations();&lt;3&gt; for (ConstraintViolation&lt;?&gt; constraintViolation : cves) { System.out.println(constraintViolation.getMessage()); } Map map = new HashMap(); map.put(&quot;errorCode&quot;,500); return map; } } ","link":"https://maodou38.github.io/validation/"},{"title":"Intellij 使用","content":"配置lombok Settings--&gt;Plugins--&gt;安装lombok插件 Settings--&gt;Build，Execution，Deployment--&gt;Compiler--&gt;Annotation Processors--&gt;Enable annotation processing 快捷键 1.编辑 快捷键 中文说明 Ctrl + Space 补全代码，由于经常与操作系统的输入法的切换冲突，所以实际很少用。一般直接在 idea 中开启输入自动补全机制。 Ctrl + Shift + Space 在列出的可选项中只显示出你所输入的关键字最相关的信息。（常用） Ctrl + Shift + ↑/↓ 代码向上下移动一行 ** (常用) ** Ctrl + Alt + V 自动返回对象 （常用） Ctrl + Shift + Enter 代码补全后，自动在代码末尾添加分号结束符 Ctrl + P 在某个方法中，调用该按键后，会展示出这个方法的调用参数列表信息。 Ctrl + Q 展示某个类或者方法的 API 说明文档 Ctrl + mouse 跳进到某个类或者方法源代码中进行查看。（常用） Alt + Insert 自动生成某个类的 Getters, Setters, Constructors, hashCode/equals, toString 等代码。（常用） Ctrl + O 展示该类中所有覆盖或者实现的方法列表，注意这里是字母小写的 O！ Ctrl + Alt + T 自动生成具有环绕性质的代码，比如：if…else,try…catch, for, synchronized 等等，使用前要先选择好需要环绕的代码块。（常用） Ctrl + / 对单行代码，添加或删除注释。分为两种情况：如果只是光标停留在某行，那么连续使用该快捷键，会不断注释掉下一行的代码；如果选定了某行代码（选定了某行代码一部分也算这种情况），那么连续使用该快捷键，会在添加或删除该行注释之间来回切换。（常用） Ctrl + Shift + / 对代码块，添加或删除注释。它与 Ctrl + / 的区别是，它只会在代码块的开头与结尾添加注释符号！（常用） Ctrl + W 选中当前光标所在的代码块，多次触发，代码块会逐级变大。（常用） Ctrl + Shift + W 是 Ctrl + W 的反向操作，多次触发，代码块会逐级变小，最小变为光标。 Alt + Q 展示包含当前光标所在代码的父节点信息，比如在 java 方法中调用，就会展示方法签名信息。 Alt + Enter 展示当前当前光标所在代码，可以变化的扩展操作 Ctrl + Alt + L 格式化代码 （常用） Ctrl + Alt + O 去除没有实际用到的包，这在 java 类中特别有用。（常用） Ctrl + Alt + I 按照缩进的设定，自动缩进所选择的代码段。 Tab / Shift + Tab 缩进或者不缩进一次所选择的代码段。（常用） Ctrl + X 或 Shift Delete 剪切当前代码。 （常用） Ctrl + C 或 Ctrl + Insert 拷贝当前代码。 （常用） Ctrl + V 或 Shift + Insert 粘贴之前剪切或拷贝的代码。（常用） Ctrl + Shift + V 从之前的剪切或拷贝的代码历史记录中，选择现在需要粘贴的内容。（常用） Ctrl + D 复制当前选中的代码。（常用） Ctrl + Y 删除当前光标所在的代码行。（常用） Ctrl + Shift + J 把下一行的代码接续到当前的代码行。 Ctrl + Enter 当前代码行与下一行代码之间插入一个空行，原来所在的光标不变。（常用） Shift + Enter 当前代码行与下一行代码之间插入一个空行，原来光标现在处于新加的空行上。（常用） Ctrl + Shift + U 所选择的内容进行大小写转换。。（常用） Ctrl + Shift + ]/[ 从当前光标所在位置开始，一直选择到当前光标所在代码段起始或者结束位置。 Ctrl + Delete 删除从当前光标所在位置开始，直到这个单词的结尾的内容。 Ctrl + NumPad(+/-) 展开或收缩代码段。 （常用） Ctrl + Shift + NumPad(+) 展开所有代码段。 Ctrl + Shift + NumPad(-) 收缩所有代码段。 Ctrl + F4 关闭当前标签页。 Shift + F6 修改名字。（常用） 1.1 Ctrl + Shift + Space 示例（智能补全） 使用前，用于补全的列表，默认是以输入的关键字作为前缀的： 使用后，用于补全的列表，会把与输入的关键字最相关的信息排到最前面，比如这里的 Resource 的实现类会直接过滤出来，很方便吧 O(∩_∩)O~： 1.2 Ctrl + P 示例（方法参数列表） 1.3 Ctrl + Q 示例（API 说明文档） 不大好用，字体太小了，还不如直接 [ctrl + 点击] 看源代码来的方便！ 1.4 Alt + Insert 示例（自动生成与类相关的代码） 如果绑定了 Spring 框架，还能自动生成与 Spring 相关的依赖参数哦： 1.5 Ctrl + O 示例（该类中所有覆盖或者实现的方法列表） 1.6 Ctrl + Alt + T 示例（生成具有环绕性质的代码） 在右边的 Surround with 列表，就是目前支持的自动代码环绕功能，可以直接通过列表最左边的快捷键选择，是不是很方便呀 O(∩_∩)O~ 它还支持自定义的代码模板（Live templates）呢，很强大吧。 1.7 Ctrl + Shift + V 示例（剪切或拷贝的代码历史记录中，选择粘贴的内容） 这是一个很酷的功能 O(∩_∩)O~，它会把之前剪切或拷贝的代码历史记录（最近 5 条）展示出来，让你来选择哦。可惜的是，列表选项如果是中文会乱码，还好内容可以正常显示： 2.查找或替换 快捷键 中文说明 Ctrl + F 在当前标签页中进行查找，还支持正则表达式哦。（常用） F3 如果找到了多个查找结果，每调用一次就会跳到下一个结果，很方便哦。 Shift + F3 是 F3 的反向操作，即每调用一次就会跳到上一个结果。 Ctrl + R 在当前标签页中进行替换操作。（常用） Ctrl + Shift + F 通过路径查找。（常用） Ctrl + Shift + R 通过路径替换。（常用） 2.1 Ctrl + F （查找） 触发后，会打开一个查找面板： 触发后，会打开一个查找面板： 图示 说明 向上箭头 就是 快捷键【Shift + F3】，每调用一次就会跳到上一个结果。 向下箭头 就是 快捷键【F3】，每调用一次就会跳到下一个结果。 加号符号 把当前的高亮项加入到选中的列表中。 减号符号 把当前的高亮项从选中的列表中移除。 勾选符号 把所有的查找结果同时选中，这很适合批量操作。 文本内的向上箭头 打开查询结果列表面板。 两个框加一个向下箭头 更多选项。 Match Case 是否大小写敏感。 Regex 正则表达式。 Words 匹配单词。 x matches x 表示的是找到的记录数。 勾选符号选中效果： 点击文本内的向上箭头，打开后的查询结果列表面板： 两个框加一个向下箭头，会变成一个大文本输入框，而且还多出一个查看搜索历史的按钮： 2.2 Ctrl + Shift + F （通过路径查找） 3.查看使用情况 快捷键 中文说明 Alt + F7 在当前项目中的使用情况，会打开一个使用情况面板。 Ctrl + F7 在当前文件中的使用情况，找的内容会低亮显示。 Ctrl + Shift + F7 在当前文件中的使用情况，找的内容会高亮显示。 Ctrl + Alt + F7 打开使用情况列表。 （常用） 3.1 Ctrl + Alt + F7（打开使用情况列表） 4.编译与运行 快捷键 中文说明 Ctrl + F9 Make project 编译项目（如果之前有编译过，那么只会编译那些修改的类或者依赖的包）。 Ctrl + Shift + F9 编译所中的范围（如果在某个类中，那么只会编译当前类）。 Alt + Shift + F10 会打开一个已经配置的运行列表，让你选择一个后，再运行。 Alt + Shift + F9 会打开一个已经配置的运行列表，让你选择一个后，再以调试模式运行。 Shift + F10 立即运行当前配置的运行实例，这个在单元测试中特别好用。 （常用） Shift + F9 立即以编译模式运行当前配置的运行实例。 Ctrl + Shift + F10 按照编辑器绑定的文件类型，运行相关的程序。比如一个 html 页面，调用后，会直接打开一个浏览器。 4.1 Alt + Shift + F10（打开运行列表，选择一个运行） 5.调试 快捷键 中文说明 F8 跳到当前代码下一行。 （常用） F7 跳入到调用的方法内部代码。 （常用） Shift + F7 会打开一个面板，让你选择具体要跳入的类方法，这个在复杂的嵌套代码中特别有用。 Shift + F8 跳出当前的类，到上一级。 （常用） Alt + F9 让代码运行到当前光标所在处，非常棒的功能。 （常用） Alt + F8 打开一个表达式面板，然后进行进一步的计算。 F9 结束当前断点的本轮调试（因为有可能代码会被调用多次，所以调用后只会结束当前的这一次）；如果有下一个断点会跳到下一个断点中。（常用） Ctrl + F8 在当前光标处，添加或者删除断点。 Ctrl + Shift + F8 打开当前断点的面板，可以进行条件过滤哦。 5.1 Shift + F7（选择具体要跳入的类方法） 5.2 Alt + F8 （计算表达式） 注意：要在当前断点之前的代码中，选择某一个变量运行才有效，因为只有代码运行过了，才会有值的呀 O(∩_∩)O~ 5.3 Ctrl + Shift + F8 （当前断点的面板） 6.导航 快捷键 中文说明 Ctrl + N 打开类查询框。（常用） Ctrl + Shift + N 打开文件查询框。（常用） Ctrl + Alt + Shift + N 打开文本查询框。 Alt + 右箭头/左箭头 跳到下一个/上一个编辑器标签。 F12 如果当前在编辑窗口，触发后，会跳到之前操作过的工具栏上。 ESC 从工具栏上，再跳回原来的编辑窗口，一般与 F12 配合使用。 Shift + ESC 隐藏最后一个处于活跃状态的工具窗口。 Ctrl + Shift + F4 同时关闭处于活动状态的某些工具栏窗口。 Ctrl + G 跳转至某一行代码。。（常用） Ctrl + E 打开曾经操作过的文件历史列表。 Ctrl + Alt + 右箭头/左箭头 在曾经浏览过的代码行中来回跳 Ctrl + Shift + Backspace 跳转到最近的编辑位置（如果曾经编辑过代码）。 Alt + F1 打开一个类型列表，选择后会导航到当前文件或者内容的具体与类型相关的面板中。 Ctrl + B 或 Ctrl + 鼠标左键 如果是类，那么会跳转到当前光标所在的类定义或者接口；如果是变量，会打开一个变量被引用的列表。（常用） Ctrl + Alt + B 跳转到实现类，而不是接口。（常用） Ctrl + Shift + I 打开一个面板，里面包含类代码。 Ctrl + Shift + B 打开变量的类型所对应的类代码，只对变量有用。 Ctrl + U 打开方法的超类方法或者类的超类，只对有超类的方法或者类有效。 Alt + 上/下箭头 在某个类中，跳到上一个/下一个方法的签名上。 Ctrl + ]/[ 移动光标到类定义的终止右大括号或者起始左大括号。 Ctrl + F12 打开类的结构列表。（常用） Ctrl + H 打开类的继承关系列表。（常用） Ctrl + Shift + H 打开某个类方法的继承关系列表。 Ctrl + Alt + H 打开所有类的方法列表，这些方法都调用了当前光标所处的某个类方法。（常用） F2/Shift + F2 在编译错误的代码行中来回跳。 F4 打开当前光标所在处的方法或类源码。 Alt + Home 激活包路径的导航栏。 F11 把光标所处的代码行添加为书签或者从书签中删除。（常用） Ctrl + F11 把光标所处的代码行添加为带快捷键的书签或者从快捷键书签中删除。 Ctrl + [0-9] 跳转到之前定义的快捷键书签。 Shift + F11 打开书签列表。（常用） 6.1 Ctrl + N （打开类查询框） 键入类名的关键字，会自动出现相关的类哦，右侧还有一个勾选项，能够把引用的 jar 包中的类也加进来，很强大 O(∩_∩)O~ 6.2 Ctrl + Alt + 右箭头/左箭头（在曾经浏览过的代码行中来回跳） 如果操作系统装的是 NVIDIA 显卡驱动程序，那么触发这个热键，会把旋转显示内容，而不是触发 idea 的功能，因为 idea 热键被 NVIDIA 显卡驱动给劫持咯。 解决方法是禁用 NVIDIA 显卡驱动所有快捷键，： 1、控制面板-》显示-》屏幕分辨率： 2、点击【高级设置】-》核芯显卡控制面板： 3、图形属性-》选项与支持-》禁用所有快捷键（这些快捷键几乎没有什么用处！） 6.3 Alt + F1（打开一个类型列表） 6.4 F11（添加为书签或者从书签中删除） 书签不是默认视图，所以我们要把它添加到当前视图中：View -&gt; Tool Windows -&gt; Favorites，打开 Favorites 面板： Favorites 面板中的 Bookmarks 就是我们添加的书签哦： 或者直接使用 Shift + F11，打开书签列表也可以的哦 O(∩_∩)O~。 6.5 Ctrl + F11 （添加或删除带快捷键的书签） 会打开一个设置快捷键的面板，比如这里点击了 1，那么它的快捷键就是 Ctrl + 1。 注意不要选择面板提供的 26 个大写字母，因为这会与 idea 的其他快捷键冲突，不知道 idea 为什么要把它们放在这里？好奇怪 O(∩_∩)O~ ","link":"https://maodou38.github.io/intellij/"},{"title":"基于 Docker 安装 Jenkins","content":"docker-compose Jenkins 是一个简单易用的持续集成软件平台，我们依然采用 Docker 的方式部署，docker-compose.yml 配置文件如下： version: '3.1' services: jenkins: restart: always image: jenkinsci/jenkins container_name: jenkins ports: # 发布端口 - 8080:8080 # 基于 JNLP 的 Jenkins 代理通过 TCP 端口 50000 与 Jenkins master 进行通信 - 50000:50000 environment: TZ: Asia/Shanghai volumes: - ./data:/var/jenkins_home 安装过程中会出现 Docker 数据卷 权限问题，用以下命令解决： chown -R 1000 /usr/local/docker/jenkins/data 解锁 Jenkins Jenkins 第一次启动时需要输入一个初始密码用以解锁安装流程，使用 docker logs jenkins 即可方便的查看到初始密码 注意： 安装时可能会因为网速等原因导致安装时间比较长，请大家耐心等待。如果长时间停留在安装页没反应，请尝试使用 F5 刷新一下。 使用自定义插件的方式安装 插件是 Jenkins 的核心，其丰富的插件（截止到 2018.10.29 共有 77350 个插件）可以满足不同人群的不同需求 插件地址：https://plugins.jenkins.io/ 注意： 除了默认勾选的插件外，一定要勾选 Publish over SSH 插件，这是我们实现持续交付的重点插件。 开始安装了，根据网络情况，安装时间可能会比较长，请耐心等待 很多插件装不上怎么办？不要慌，记住这些插件的名字，咱们稍后可以手动安装 安装成功效果图 创建管理员 安装完成，进入首页 附：Jenkins 手动安装插件 使用插件管理器安装 Manage Jenkins -&gt; Manage Plugins -&gt; Avaliable 过滤出想要安装的插件，然后点击 Download now and install after restart 手动上传 .hpi 文件 点击进入插件中心 点击 Archives 下载需要的版本 在插件管理器中选择 Advanced 选择上传即可 重启 Jenkins docker-compose down docker-compose up -d 注意： 请留意需要下载插件的警告信息，如果不满足安装条件，Jenkins 是会拒绝安装的。如下图： ","link":"https://maodou38.github.io/jenkins-install/"},{"title":"使用FastDFS","content":"安装 FastDFS Java 客户端 从 GitHub 克隆源码 git clone https://github.com/happyfish100/fastdfs-client-java.git 从源码安装并部署到 Nexus 部署前别忘记在 pom.xml 中增加 Nexus 相关配置，配置代码如下： &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://192.168.75.128:8081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://192.168.75.128:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; mvn clean install deploy 在项目中添加依赖 &lt;!-- FastDFS Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.csource&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt; &lt;version&gt;1.27-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- FastDFS End --&gt; 创建 FastDFS 工具类 定义文件存储服务接口 /** * 文件存储服务接口 * &lt;p&gt;Title: StorageService&lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * * @author Lusifer * @version 1.0.0 * @date 2018/8/14 5:22 */ public interface StorageService { /** * 上传文件 * * @param data 文件的二进制内容 * @param extName 扩展名 * @return 上传成功后返回生成的文件id；失败，返回null */ public String upload(byte[] data, String extName); /** * 删除文件 * * @param fileId 被删除的文件id * @return 删除成功后返回0，失败后返回错误代码 */ public int delete(String fileId); } 实现文件存储服务接口 import org.csource.common.NameValuePair; import org.csource.fastdfs.ClientGlobal; import org.csource.fastdfs.StorageClient1; import org.csource.fastdfs.StorageServer; import org.csource.fastdfs.TrackerClient; import org.csource.fastdfs.TrackerGroup; import org.csource.fastdfs.TrackerServer; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.InitializingBean; import org.springframework.beans.factory.annotation.Value; import java.io.File; import java.io.FileWriter; import java.io.IOException; import java.io.PrintWriter; /** * 文件存储服务实现 * &lt;p&gt;Title: FastDFSStorageService&lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * * @author Lusifer * @version 1.0.0 * @date 2018/8/14 5:27 */ public class FastDFSStorageService implements StorageService, InitializingBean { private static final Logger logger = LoggerFactory.getLogger(FastDFSStorageService.class); private TrackerClient trackerClient; @Value(&quot;${storage.fastdfs.tracker_server}&quot;) private String trackerServer; @Override public String upload(byte[] data, String extName) { TrackerServer trackerServer = null; StorageServer storageServer = null; StorageClient1 storageClient1 = null; try { NameValuePair[] meta_list = null; // new NameValuePair[0]; trackerServer = trackerClient.getConnection(); if (trackerServer == null) { logger.error(&quot;getConnection return null&quot;); } storageServer = trackerClient.getStoreStorage(trackerServer); storageClient1 = new StorageClient1(trackerServer, storageServer); String fileid = storageClient1.upload_file1(data, extName, meta_list); logger.debug(&quot;uploaded file &lt;{}&gt;&quot;, fileid); return fileid; } catch (Exception ex) { logger.error(&quot;Upload fail&quot;, ex); return null; } finally { if (storageServer != null) { try { storageServer.close(); } catch (IOException e) { e.printStackTrace(); } } if (trackerServer != null) { try { trackerServer.close(); } catch (IOException e) { e.printStackTrace(); } } storageClient1 = null; } } @Override public int delete(String fileId) { // System.out.println(&quot;deleting ....&quot;); TrackerServer trackerServer = null; StorageServer storageServer = null; StorageClient1 storageClient1 = null; int index = fileId.indexOf('/'); String groupName = fileId.substring(0, index); try { trackerServer = trackerClient.getConnection(); if (trackerServer == null) { logger.error(&quot;getConnection return null&quot;); } storageServer = trackerClient.getStoreStorage(trackerServer, groupName); storageClient1 = new StorageClient1(trackerServer, storageServer); int result = storageClient1.delete_file1(fileId); return result; } catch (Exception ex) { logger.error(&quot;Delete fail&quot;, ex); return 1; } finally { if (storageServer != null) { try { storageServer.close(); } catch (IOException e) { e.printStackTrace(); } } if (trackerServer != null) { try { trackerServer.close(); } catch (IOException e) { e.printStackTrace(); } } storageClient1 = null; } } @Override public void afterPropertiesSet() throws Exception { File confFile = File.createTempFile(&quot;fastdfs&quot;, &quot;.conf&quot;); PrintWriter confWriter = new PrintWriter(new FileWriter(confFile)); confWriter.println(&quot;tracker_server=&quot; + trackerServer); confWriter.close(); ClientGlobal.init(confFile.getAbsolutePath()); confFile.delete(); TrackerGroup trackerGroup = ClientGlobal.g_tracker_group; trackerClient = new TrackerClient(trackerGroup); logger.info(&quot;Init FastDFS with tracker_server : {}&quot;, trackerServer); } } 文件存储服务工厂类 import org.springframework.beans.factory.FactoryBean; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.beans.factory.config.AutowireCapableBeanFactory; import java.util.HashMap; import java.util.Map; /** * 文件存储服务工厂类 * &lt;p&gt;Title: StorageFactory&lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * * @author Lusifer * @version 1.0.0 * @date 2018/8/14 5:28 */ public class StorageFactory implements FactoryBean&lt;StorageService&gt; { @Autowired private AutowireCapableBeanFactory acbf; /** * 存储服务的类型，目前仅支持fastdfs */ @Value(&quot;${storage.type}&quot;) private String type; private Map&lt;String, Class&lt;? extends StorageService&gt;&gt; classMap; public StorageFactory() { classMap = new HashMap&lt;&gt;(); classMap.put(&quot;fastdfs&quot;, FastDFSStorageService.class); } @Override public StorageService getObject() throws Exception { Class&lt;? extends StorageService&gt; clazz = classMap.get(type); if (clazz == null) { throw new RuntimeException(&quot;Unsupported storage type [&quot; + type + &quot;], valid are &quot; + classMap.keySet()); } StorageService bean = clazz.newInstance(); acbf.autowireBean(bean); acbf.initializeBean(bean, bean.getClass().getSimpleName()); return bean; } @Override public Class&lt;?&gt; getObjectType() { return StorageService.class; } @Override public boolean isSingleton() { return true; } } 配置文件存储服务工厂类 import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * Java 配置方式定义 StorageFactory 的 Bean 使其可以被依赖注入 * &lt;p&gt;Title: FastDFSConfiguration&lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * * @author Lusifer * @version 1.0.0 * @date 2018/8/14 5:28 */ @Configuration public class FastDFSConfiguration { @Bean public StorageFactory storageFactory() { return new StorageFactory(); } } 创建 FastDFS 控制器 增加云配置 fastdfs.base.url: http://192.168.75.128:8888/ storage: type: fastdfs fastdfs: tracker_server: 192.168.75.128:22122 控制器代码 import com.funtl.itoken.service.upload.fastdfs.StorageService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.CrossOrigin; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.multipart.MultipartFile; import java.io.IOException; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; @CrossOrigin(origins = &quot;*&quot;, maxAge = 3600) @RestController public class UploadController { @Value(&quot;${fastdfs.base.url}&quot;) private String FASTDFS_BASE_URL; @Autowired private StorageService storageService; /** * 文件上传 * * @param dropFile Dropzone * @param editorFiles wangEditor * @return */ @RequestMapping(value = &quot;upload&quot;, method = RequestMethod.POST) public Map&lt;String, Object&gt; upload(MultipartFile dropFile, MultipartFile[] editorFiles) { Map&lt;String, Object&gt; result = new HashMap&lt;&gt;(); // Dropzone 上传 if (dropFile != null) { result.put(&quot;fileName&quot;, writeFile(dropFile)); } // wangEditor 上传 if (editorFiles != null &amp;&amp; editorFiles.length &gt; 0) { List&lt;String&gt; fileNames = new ArrayList&lt;&gt;(); for (MultipartFile editorFile : editorFiles) { fileNames.add(writeFile(editorFile)); } result.put(&quot;errno&quot;, 0); result.put(&quot;data&quot;, fileNames); } return result; } /** * 将图片写入指定目录 * * @param multipartFile * @return 返回文件完整路径 */ private String writeFile(MultipartFile multipartFile) { // 获取文件后缀 String oName = multipartFile.getOriginalFilename(); String extName = oName.substring(oName.lastIndexOf(&quot;.&quot;) + 1); // 文件存放路径 String url = null; try { String uploadUrl = storageService.upload(multipartFile.getBytes(), extName); url = FASTDFS_BASE_URL + uploadUrl; } catch (IOException e) { e.printStackTrace(); } // 返回文件完整路径 return url; } } ","link":"https://maodou38.github.io/use-fastdfs/"},{"title":"SpringBoot2.X整合","content":"整合redis 依赖 &lt;!-- spring boot redis 缓存引入 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- lettuce pool 缓存连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; application.properties配置文件 # Redis数据库索引（默认为0） spring.redis.database=0 # Redis服务器地址 spring.redis.host=localhost # Redis服务器连接端口 spring.redis.port=6379 # Redis服务器连接密码（默认为空） spring.redis.password= # 连接池最大连接数（使用负值表示没有限制） 默认 8 spring.redis.lettuce.pool.max-active=8 # 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1 spring.redis.lettuce.pool.max-wait=-1 # 连接池中的最大空闲连接 默认 8 spring.redis.lettuce.pool.max-idle=8 新建config包，创建RedisConfig类 默认情况下RedisTemplate模板只能支持字符串，我们自定义一个RedisTemplate，设置序列化器，这样我们可以很方便的操作实例对象。 @Configuration public class RedisConfig { @Bean public RedisTemplate&lt;String, Serializable&gt; redisTemplate(LettuceConnectionFactory connectionFactory) { RedisTemplate&lt;String, Serializable&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new GenericJackson2JsonRedisSerializer()); redisTemplate.setConnectionFactory(connectionFactory); return redisTemplate; } } ","link":"https://maodou38.github.io/springboot2.X-workWithOthers/"},{"title":"使用swagger接口文档引擎","content":"Maven 增加 Swagger2 所需依赖，pom.xml 配置如下： &lt;!-- Swagger2 Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Swagger2 End --&gt; 配置 Swagger2 注意：RequestHandlerSelectors.basePackage(&quot;ran.ding.service.admin.controller&quot;) 为 Controller 包路径，不然生成的文档扫描不到接口 创建一个名为 Swagger2Config 的 Java 配置类，代码如下： package ran.ding.service.admin.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; @Configuration public class Swagger2Config { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(&quot;com.funtl.itoken.service.admin.controller&quot;)) .paths(PathSelectors.any()) .build(); } private ApiInfo apiInfo() { return new ApiInfoBuilder() .title(&quot;iToken API 文档&quot;) .description(&quot;iToken API 网关接口，http://www.funtl.com&quot;) .termsOfServiceUrl(&quot;http://www.funtl.com&quot;) .version(&quot;1.0.0&quot;) .build(); } } 启用 Swagger2 Application 中加上注解 @EnableSwagger2 表示开启 Swagger package ran.ding.service.admin; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; import springfox.documentation.swagger2.annotations.EnableSwagger2; import tk.mybatis.spring.annotation.MapperScan; @SpringBootApplication(scanBasePackages = &quot;com.funtl.itoken&quot;) @EnableEurekaClient @EnableSwagger2 @MapperScan(basePackages = {&quot;com.funtl.itoken.common.mapper&quot;, &quot;com.funtl.itoken.service.admin.mapper&quot;}) public class ServiceAdminApplication { public static void main(String[] args) { SpringApplication.run(ServiceAdminApplication.class, args); } } 使用 Swagger2 在 Controller 中增加 Swagger2 相关注解，代码如下： /** * 分页查询 * * @param pageNum * @param pageSize * @param tbSysUserJson * @return */ @ApiOperation(value = &quot;管理员分页查询&quot;) @ApiImplicitParams({ @ApiImplicitParam(name = &quot;pageNum&quot;, value = &quot;页码&quot;, required = true, dataType = &quot;int&quot;, paramType = &quot;path&quot;), @ApiImplicitParam(name = &quot;pageSize&quot;, value = &quot;笔数&quot;, required = true, dataType = &quot;int&quot;, paramType = &quot;path&quot;), @ApiImplicitParam(name = &quot;tbSysUserJson&quot;, value = &quot;管理员对象 JSON 字符串&quot;, required = false, dataTypeClass = String.class, paramType = &quot;json&quot;) }) @RequestMapping(value = &quot;page/{pageNum}/{pageSize}&quot;, method = RequestMethod.GET) public BaseResult page( @PathVariable(required = true) int pageNum, @PathVariable(required = true) int pageSize, @RequestParam(required = false) String tbSysUserJson ) throws Exception { TbSysUser tbSysUser = null; if (tbSysUserJson != null) { tbSysUser = MapperUtils.json2pojo(tbSysUserJson, TbSysUser.class); } PageInfo pageInfo = adminService.page(pageNum, pageSize, tbSysUser); // 分页后的结果集 List&lt;TbSysUser&gt; list = pageInfo.getList(); // 封装 Cursor 对象 BaseResult.Cursor cursor = new BaseResult.Cursor(); cursor.setTotal(new Long(pageInfo.getTotal()).intValue()); cursor.setOffset(pageInfo.getPageNum()); cursor.setLimit(pageInfo.getPageSize()); return BaseResult.ok(list, cursor); } Swagger 注解说明 Swagger 通过注解表明该接口会生成文档，包括接口名、请求方法、参数、返回信息的等等。 @Api：修饰整个类，描述 Controller 的作用 @ApiOperation：描述一个类的一个方法，或者说一个接口 @ApiParam：单个参数描述 @ApiModel：用对象来接收参数 @ApiProperty：用对象接收参数时，描述对象的一个字段 @ApiResponse：HTTP 响应其中 1 个描述 @ApiResponses：HTTP 响应整体描述 @ApiIgnore：使用该注解忽略这个API @ApiError：发生错误返回的信息 @ApiImplicitParam：一个请求参数 @ApiImplicitParams：多个请求参数 访问 Swagger2 访问地址：http://ip:port/swagger-ui.html ","link":"https://maodou38.github.io/swagger-use/"},{"title":"SpringBoot——Mybatis配置Redis二级缓存","content":"一级缓存 MyBatis 会在表示会话的 SqlSession 对象中建立一个简单的缓存，将每次查询到的结果结果缓存起来，当下次查询的时候，如果判断先前有个完全一样的查询，会直接从缓存中直接将结果取出，返回给用户，不需要再进行一次数据库查询了。 一级缓存是 SqlSession 级别的缓存。在操作数据库时需要构造 sqlSession 对象，在对象中有一个（内存区域）数据结构（HashMap）用于存储缓存数据。不同的 sqlSession 之间的缓存数据区域（HashMap）是互相不影响的。其作用域是同一个 SqlSession，在同一个 sqlSession 中两次执行相同的 sql 语句，第一次执行完毕会将数据库中查询的数据写到缓存（内存），第二次会从缓存中获取数据将不再从数据库查询，从而提高查询效率。当一个 sqlSession 结束后该 sqlSession 中的一级缓存也就不存在了。Mybatis 默认开启一级缓存。 二级缓存 二级缓存是 mapper 级别的缓存，多个 SqlSession 去操作同一个 Mapper 的 sql 语句，多个 SqlSession 去操作数据库得到数据会存在二级缓存区域，多个 SqlSession 可以共用二级缓存，二级缓存是跨 SqlSession 的。其作用域是 mapper 的同一个 namespace，不同的 sqlSession 两次执行相同 namespace下的 sql 语句且向 sql 中传递参数也相同即最终执行相同的 sql 语句，第一次执行完毕会将数据库中查询的数据写到缓存（内存），第二次会从缓存中获取数据将不再从数据库查询，从而提高查询效率。Mybatis 默认没有开启二级缓存需要在 setting 全局参数中配置开启二级缓存。 开启 MyBatis 二级缓存 在 Spring Boot 配置文件中开启 MyBatis 二级缓存，配置代码如下： mybatis: configuration: cache-enabled: true 实体类实现序列化接口并声明序列号 private static final long serialVersionUID = 8289770415244673535L; IDEA 提示生成序列号 默认情况下 Intellij IDEA 不会提示继承了 Serializable 接口的类生成 serialVersionUID 的警告。如果需要生成 serialVersionUID，需要手动配置。 File -&gt; Settings -&gt; Inspections -&gt; Serialization issues -&gt; Serialization class without 'serialVersionUID' 创建相关工具类 实现 Spring ApplicationContextAware 接口，用于手动注入 Bean 创建一个名为 ApplicationContextHolder 的工具类，代码如下： import org.apache.commons.lang3.Validate; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.BeansException; import org.springframework.beans.factory.DisposableBean; import org.springframework.context.ApplicationContext; import org.springframework.context.ApplicationContextAware; import org.springframework.stereotype.Component; @Component public class ApplicationContextHolder implements ApplicationContextAware, DisposableBean { private static final Logger logger = LoggerFactory.getLogger(ApplicationContextHolder.class); private static ApplicationContext applicationContext; /** * 获取存储在静态变量中的 ApplicationContext * * @return */ public static ApplicationContext getApplicationContext() { assertContextInjected(); return applicationContext; } /** * 从静态变量 applicationContext 中获取 Bean，自动转型成所赋值对象的类型 * * @param name * @param &lt;T&gt; * @return */ public static &lt;T&gt; T getBean(String name) { assertContextInjected(); return (T) applicationContext.getBean(name); } /** * 从静态变量 applicationContext 中获取 Bean，自动转型成所赋值对象的类型 * * @param clazz * @param &lt;T&gt; * @return */ public static &lt;T&gt; T getBean(Class&lt;T&gt; clazz) { assertContextInjected(); return applicationContext.getBean(clazz); } /** * 实现 DisposableBean 接口，在 Context 关闭时清理静态变量 * * @throws Exception */ public void destroy() throws Exception { logger.debug(&quot;清除 SpringContext 中的 ApplicationContext: {}&quot;, applicationContext); applicationContext = null; } /** * 实现 ApplicationContextAware 接口，注入 Context 到静态变量中 * * @param applicationContext * @throws BeansException */ public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { ApplicationContextHolder.applicationContext = applicationContext; } /** * 断言 Context 已经注入 */ private static void assertContextInjected() { Validate.validState(applicationContext != null, &quot;applicationContext 属性未注入，请在 spring-context.xml 配置中定义 ApplicationContextHolder&quot;); } } 实现 MyBatis Cache 接口，用于自定义缓存为 Redis 创建一个名为 RedisCache 的工具类，代码如下： import com.funtl.itoken.common.context.ApplicationContextHolder; import org.apache.ibatis.cache.Cache; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.data.redis.core.RedisCallback; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.core.ValueOperations; import java.util.concurrent.TimeUnit; import java.util.concurrent.locks.ReadWriteLock; import java.util.concurrent.locks.ReentrantReadWriteLock; /** * Redis 缓存工具类 * &lt;p&gt;Title: RedisCache&lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * * @author Lusifer * @version 1.0.0 * @date 2018/8/13 6:03 */ public class RedisCache implements Cache { private static final Logger logger = LoggerFactory.getLogger(RedisCache.class); private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); private final String id; // cache instance id private RedisTemplate redisTemplate; private static final long EXPIRE_TIME_IN_MINUTES = 30; // redis过期时间 public RedisCache(String id) { if (id == null) { throw new IllegalArgumentException(&quot;Cache instances require an ID&quot;); } this.id = id; } @Override public String getId() { return id; } /** * Put query result to redis * * @param key * @param value */ @Override public void putObject(Object key, Object value) { try { RedisTemplate redisTemplate = getRedisTemplate(); ValueOperations opsForValue = redisTemplate.opsForValue(); opsForValue.set(key, value, EXPIRE_TIME_IN_MINUTES, TimeUnit.MINUTES); logger.debug(&quot;Put query result to redis&quot;); } catch (Throwable t) { logger.error(&quot;Redis put failed&quot;, t); } } /** * Get cached query result from redis * * @param key * @return */ @Override public Object getObject(Object key) { try { RedisTemplate redisTemplate = getRedisTemplate(); ValueOperations opsForValue = redisTemplate.opsForValue(); logger.debug(&quot;Get cached query result from redis&quot;); // System.out.println(&quot;****&quot; + opsForValue.get(key).toString()); return opsForValue.get(key); } catch (Throwable t) { logger.error(&quot;Redis get failed, fail over to db&quot;, t); return null; } } /** * Remove cached query result from redis * * @param key * @return */ @Override @SuppressWarnings(&quot;unchecked&quot;) public Object removeObject(Object key) { try { RedisTemplate redisTemplate = getRedisTemplate(); redisTemplate.delete(key); logger.debug(&quot;Remove cached query result from redis&quot;); } catch (Throwable t) { logger.error(&quot;Redis remove failed&quot;, t); } return null; } /** * Clears this cache instance */ @Override public void clear() { RedisTemplate redisTemplate = getRedisTemplate(); redisTemplate.execute((RedisCallback) connection -&gt; { connection.flushDb(); return null; }); logger.debug(&quot;Clear all the cached query result from redis&quot;); } /** * This method is not used * * @return */ @Override public int getSize() { return 0; } @Override public ReadWriteLock getReadWriteLock() { return readWriteLock; } private RedisTemplate getRedisTemplate() { if (redisTemplate == null) { redisTemplate = ApplicationContextHolder.getBean(&quot;redisTemplate&quot;); } return redisTemplate; } } Mapper 接口中增加注解 在 Mapper 接口中增加注解，声明需要使用二级缓存 import com.funtl.itoken.common.domain.TbSysUser; import com.funtl.itoken.common.utils.RedisCache; import org.apache.ibatis.annotations.CacheNamespace; import tk.mybatis.mapper.MyMapper; @CacheNamespace(implementation = RedisCache.class) public interface TbSysUserMapper extends MyMapper&lt;TbSysUser&gt; { } ","link":"https://maodou38.github.io/mybatis-redis-cache/"},{"title":"各种资源地址整理","content":"pandas中文文档 redis命令大全 单点登录—CAS RabbitMQ MyBatis-Plus 搭建FastDFS 单点登录—CAS 初识SSO 搭建基础服务 多种认证方式 自定义认证登录策略 Service配置及管理 自定义登录界面和表单信息 自定义验证码以及自定义错误信息 多属性返回 客户端接入 通过Restful协议请求认证和退出 单点退出 集群部署 客户端前后端分离接入 RabbitMQ 初识RabbitMQ AMQP协议 探索交换机(Exchange)，结合SpringBoot实战 消息分发机制 消息确认机制(AMQP事务) 消息确认机制(Confirm模式) 权限管理 做WebSocket消息代理，集成Spring Boot实现消息实时推送 ","link":"https://maodou38.github.io/useful-urls/"},{"title":"Linux日常操作","content":"#目录 修改SSH默认端口 开启BBR 修改SSH默认端口 1 修改端口 vi /etc/ssh/sshd_config #找到Port XX 修改为自己想要的端口 2 防火墙放行 #修改XXX为上面修改后端口 firewall-cmd --zone=public --add-port=XXX/tcp --permanent # 刷新防火墙规则 firewall-cmd --reload #查看是否生效 firewall-cmd --zone=public --query-port=XXX/tcp 3 SELinux放行 #检查semanage是否安装 rpm -qa |grep policycoreutils-python #安装 yum install policycoreutils-python #查看当前SSH允许端口 semanage port -l |grep ssh #添加新端口 semanage port -a -t ssh_port_t -p tcp XXX #检查是否添加成功 semanage port -l |grep ssh 4 重启SSH服务 systemctl restart sshd.service 开启BBR #centos curl -O https://raw.githubusercontent.com/teddysun/across/master/bbr.sh &amp;&amp; sh bbr.sh #debian echo &quot;net.core.default_qdisc=fq&quot; &gt;&gt; /etc/sysctl.conf echo &quot;net.ipv4.tcp_congestion_control=bbr&quot; &gt;&gt; /etc/sysctl.conf #保存生效 sysctl -p #关闭BBR #debian sed -i '/net\\.core\\.default_qdisc=fq/d' /etc/sysctl.conf sed -i '/net\\.ipv4\\.tcp_congestion_control=bbr/d' /etc/sysctl.conf sysctl -p ","link":"https://maodou38.github.io/linux-use/"},{"title":"Docker Compose 模板文件","content":"常用docker-compose.yml整理 Tomcat Mysql5 Mysql8 Redis集群 Redis高可用监控 Jenkins 模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。但大家不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。 默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。 version: &quot;3&quot; services: webapp: image: examples/web ports: - &quot;80:80&quot; volumes: - &quot;/data&quot; 注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。 如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中再次设置。 下面分别介绍各个指令的用法。 build 指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。 version: '3' services: webapp: build: ./dir 你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。 使用 dockerfile 指令指定 Dockerfile 文件名。 使用 arg 指令指定构建镜像时的变量。 version: '3' services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 使用 cache_from 指定构建镜像的缓存 build: context: . cache_from: - alpine:latest - corp/web_app:3.14 cap_add, cap_drop 指定容器的内核能力（capacity）分配。 例如，让容器拥有所有能力可以指定为： cap_add: - ALL 去掉 NET_ADMIN 能力可以指定为： cap_drop: - NET_ADMIN command 覆盖容器启动后默认执行的命令。 command: echo &quot;hello world&quot; configs 仅用于 Swarm mode cgroup_parent 指定父 cgroup 组，意味着将继承该组的资源限制。 例如，创建了一个 cgroup 组名称为 cgroups_1。 cgroup_parent: cgroups_1 container_name 指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。 container_name: docker-web-container 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。 deploy 仅用于 Swarm mode devices 指定设备映射关系。 devices: - &quot;/dev/ttyUSB1:/dev/ttyUSB0&quot; #depends_on 解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web version: '3' services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 「完全启动」之后才启动。 dns 自定义 DNS 服务器。可以是一个值，也可以是一个列表。 dns: 8.8.8.8 dns: - 8.8.8.8 - 114.114.114.114 dns_search 配置 DNS 搜索域。可以是一个值，也可以是一个列表。 dns_search: example.com dns_search: - domain1.example.com - domain2.example.com tmpfs 挂载一个 tmpfs 文件系统到容器。 tmpfs: /run tmpfs: - /run - /tmp env_file 从文件中获取环境变量，可以为单独的文件路径或列表。 如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。 如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。 env_file: .env env_file: - ./common.env - ./apps/web.env - /opt/secrets.env 环境变量文件中每一行必须符合格式，支持 # 开头的注释行。 # common.env: Set development environment PROG_ENV=development environment 设置环境变量。你可以使用数组或字典两种格式。 只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。 environment: RACK_ENV: development SESSION_SECRET: environment: - RACK_ENV=development - SESSION_SECRET 如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括 y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF expose 暴露端口，但不映射到宿主机，只被连接的服务访问。 仅可以指定内部端口为参数 expose: - &quot;3000&quot; - &quot;8000&quot; external_links 注意：不建议使用该指令。 链接到 docker-compose.yml 外部的容器，甚至并非 Compose 管理的外部容器。 external_links: - redis_1 - project_db_1:mysql - project_db_1:postgresql extra_hosts 类似 Docker 中的 --add-host 参数，指定额外的 host 名称映射信息。 extra_hosts: - &quot;googledns:8.8.8.8&quot; - &quot;dockerhub:52.1.157.61&quot; 会在启动后的服务容器中 /etc/hosts 文件中添加如下两条条目。 8.8.8.8 googledns 52.1.157.61 dockerhub healthcheck 通过命令检查容器是否健康运行。 healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;] interval: 1m30s timeout: 10s retries: 3 image 指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。 image: ubuntu image: orchardup/postgresql image: a4bc65fd labels 为容器添加 Docker 元数据（metadata）信息。例如可以为容器添加辅助说明信息。 labels: com.startupteam.description: &quot;webapp for a startup team&quot; com.startupteam.department: &quot;devops department&quot; com.startupteam.release: &quot;rc3 for v1.0&quot; links 注意：不推荐使用该指令。 logging 配置日志选项。 logging: driver: syslog options: syslog-address: &quot;tcp://192.168.0.42:123&quot; 目前支持三种日志驱动类型。 driver: &quot;json-file&quot; driver: &quot;syslog&quot; driver: &quot;none&quot; options 配置日志驱动的相关参数。 options: max-size: &quot;200k&quot; max-file: &quot;10&quot; network_mode 设置网络模式。使用和 docker run 的 --network 参数一样的值。 network_mode: &quot;bridge&quot; network_mode: &quot;host&quot; network_mode: &quot;none&quot; network_mode: &quot;service:[service name]&quot; network_mode: &quot;container:[container name/id]&quot; networks 配置容器连接的网络。 version: &quot;3&quot; services: some-service: networks: - some-network - other-network networks: some-network: other-network: pid 跟主机系统共享进程命名空间。打开该选项的容器之间，以及容器和宿主机系统之间可以通过进程 ID 来相互访问和操作。 pid: &quot;host&quot; ports 暴露端口信息。 使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 ports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; 注意：当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。 secrets 存储敏感数据，例如 mysql 服务密码。 version: &quot;3.1&quot; services: mysql: image: mysql environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password secrets: - db_root_password - my_other_secret secrets: my_secret: file: ./my_secret.txt my_other_secret: external: true security_opt 指定容器模板标签（label）机制的默认属性（用户、角色、类型、级别等）。例如配置标签的用户名和角色名。 security_opt: - label:user:USER - label:role:ROLE stop_signal 设置另一个信号来停止容器。在默认情况下使用的是 SIGTERM 停止容器。 stop_signal: SIGUSR1 sysctls 配置容器内核参数。 sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0 sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 ulimits 指定容器的 ulimits 限制值。 例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。 ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes 数据卷所挂载路径设置。可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro）。 该指令中路径支持相对路径。 volumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro 其它指令 此外，还有包括 domainname, entrypoint, hostname, ipc, mac_address, privileged, read_only, shm_size, restart, stdin_open, tty, user, working_dir 等指令，基本跟 docker run 中对应参数的功能一致。 指定服务容器启动后执行的入口文件。 entrypoint: /code/entrypoint.sh 指定容器中运行应用的用户名。 user: nginx 指定容器中工作目录。 working_dir: /code 指定容器中搜索域名、主机名、mac 地址等。 domainname: your_website.com hostname: test mac_address: 08-00-27-00-0C-0A 允许容器中运行一些特权命令。 privileged: true 指定容器退出后的重启策略为始终重启。该命令对保持服务始终运行十分有效，在生产环境中推荐配置为 always 或者 unless-stopped。 restart: always 以只读模式挂载容器的 root 文件系统，意味着不能对容器内容进行修改。 read_only: true 打开标准输入，可以接受外部输入。 stdin_open: true 模拟一个伪终端。 tty: true 读取变量 Compose 模板文件支持动态读取主机的系统环境变量和当前目录下的 .env 文件中的变量。 例如，下面的 Compose 文件将从运行它的环境中读取变量 ${MONGO_VERSION} 的值，并写入执行的指令中。 version: &quot;3&quot; services: db: image: &quot;mongo:${MONGO_VERSION}&quot; 如果执行 MONGO_VERSION=3.2 docker-compose up 则会启动一个 mongo:3.2 镜像的容器；如果执行 MONGO_VERSION=2.8 docker-compose up 则会启动一个 mongo:2.8 镜像的容器。 若当前目录存在 .env 文件，执行 docker-compose 命令时将从该文件中读取变量。 在当前目录新建 .env 文件并写入以下内容。 # 支持 # 号注释 MONGO_VERSION=3.6 执行 docker-compose up 则会启动一个 mongo:3.6 镜像的容器。 Tomcat version: '3.1' services: tomcat: restart: always image: tomcat container_name: tomcat ports: - 8080:8080 volumes: - /usr/local/docker/tomcat/webapps/test:/usr/local/tomcat/webapps/test environment: TZ: Asia/Shanghai Mysql5 version: '3.1' services: mysql: restart: always image: mysql:5.7.22 container_name: mysql ports: - 3306:3306 environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: 123456 command: --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci --explicit_defaults_for_timestamp=true --lower_case_table_names=1 --max_allowed_packet=128M --sql-mode=&quot;STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO&quot; volumes: - mysql-data:/var/lib/mysql volumes: mysql-data: Mysql8 version: '3.1' services: db: image: mysql restart: always environment: MYSQL_ROOT_PASSWORD: 123456 command: --default-authentication-plugin=mysql_native_password --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci --explicit_defaults_for_timestamp=true --lower_case_table_names=1 ports: - 3306:3306 volumes: - ./data:/var/lib/mysql adminer: image: adminer restart: always ports: - 8080:8080 Redis集群 version: '3.1' services: master: image: redis container_name: redis-master ports: - 6379:6379 slave1: image: redis container_name: redis-slave-1 ports: - 6380:6379 command: redis-server --slaveof redis-master 6379 slave2: image: redis container_name: redis-slave-2 ports: - 6381:6379 command: redis-server --slaveof redis-master 6379 Sentinel集群 version: '3.1' services: sentinel1: image: redis container_name: redis-sentinel-1 ports: - 26379:26379 command: redis-sentinel /usr/local/etc/redis/sentinel.conf volumes: - ./sentinel1.conf:/usr/local/etc/redis/sentinel.conf sentinel2: image: redis container_name: redis-sentinel-2 ports: - 26380:26379 command: redis-sentinel /usr/local/etc/redis/sentinel.conf volumes: - ./sentinel2.conf:/usr/local/etc/redis/sentinel.conf sentinel3: image: redis container_name: redis-sentinel-3 ports: - 26381:26379 command: redis-sentinel /usr/local/etc/redis/sentinel.conf volumes: - ./sentinel3.conf:/usr/local/etc/redis/sentinel.conf 修改 Sentinel 配置文件 port 26379 dir /tmp # 自定义集群名，其中 127.0.0.1 为 redis-master 的 ip，6379 为 redis-master 的端口，2 为最小投票数（因为有 3 台 Sentinel 所以可以设置成 2） sentinel monitor mymaster 127.0.0.1 6379 2 sentinel down-after-milliseconds mymaster 30000 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000 sentinel deny-scripts-reconfig yes Jenkins version: '3.1' services: jenkins: restart: always image: jenkinsci/jenkins container_name: jenkins ports: # 发布端口 - 8080:8080 # 基于 JNLP 的 Jenkins 代理通过 TCP 端口 50000 与 Jenkins master 进行通信 - 50000:50000 environment: TZ: Asia/Shanghai volumes: - ./data:/var/jenkins_home 安装过程中会出现 Docker 数据卷 权限问题，用以下命令解决： chown -R 1000 /usr/local/docker/jenkins/data ","link":"https://maodou38.github.io/docker-compose-yml/"},{"title":"Dockerfile 指令","content":"指定基础镜像-FROM 运行指定命令-RUN 容器启动时要运行的命令-CMD 为镜像指定标签-LABEL 指定作者-MAINTAINER 暴漏容器运行时的监听端口给外部-EXPOSE 设置环境变量-ENV 复制命令-ADD 复制命令-COPY 启动时的默认命令-ENTRYPOINT 挂载-VOLUME 设置启动容器的用户-USER 设置工作目录-WORKDIR 设置变量-ARG 使命令只对子镜像生效-ONBUILD 当容器推出时给系统发送什么样的指令-STOPSIGNAL 容器健康状况检查-HEALTHCHECK FROM 功能为指定基础镜像，并且必须是第一条指令。 如果不以任何镜像为基础，那么写法为：FROM scratch。 同时意味着接下来所写的指令将作为镜像的第一层开始 语法： FROM &lt;image&gt; FROM &lt;image&gt;:&lt;tag&gt; FROM &lt;image&gt;:&lt;digest&gt; 三种写法，其中和 是可选项，如果没有选择，那么默认值为latest RUN 功能为运行指定的命令 RUN命令有两种格式 1. RUN &lt;command&gt; 2. RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] 第一种后边直接跟shell命令 在linux操作系统上默认 /bin/sh -c 在windows操作系统上默认 cmd /S /C 第二种是类似于函数调用。 可将executable理解成为可执行文件，后面就是两个参数。 两种写法比对： RUN /bin/bash -c 'source $HOME/.bashrc; echo $HOME RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;] 注意：多行命令不要写多个RUN，原因是Dockerfile中每一个指令都会建立一层. 多少个RUN就构建了多少层镜像，会造成镜像的臃肿、多层，不仅仅增加了构件部署的时间，还容易出错。 RUN书写时的换行符是\\ CMD 功能为容器启动时要运行的命令 语法有三种写法 1. CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] 2. CMD [&quot;param1&quot;,&quot;param2&quot;] 3. CMD command param1 param2 第三种比较好理解了，就时shell这种执行方式和写法 第一种和第二种其实都是可执行文件加上参数的形式 举例说明两种写法： CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ] CMD [ &quot;echo&quot;, &quot;$HOME&quot; ] 补充细节：这里边包括参数的一定要用双引号，就是&quot;,不能是单引号。千万不能写成单引号。 原因是参数传递后，docker解析的是一个JSON array ___ RUN &amp; CMD ___ 不要把RUN和CMD搞混了。 RUN是构件容器时就运行的命令以及提交运行结果 CMD是容器启动时执行的命令，在构件时并不运行，构件时紧紧指定了这个命令到底是个什么样子 LABEL 功能是为镜像指定标签 语法： LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ... 一个Dockerfile种可以有多个LABEL，如下： LABEL &quot;com.example.vendor&quot;=&quot;ACME Incorporated&quot; LABEL com.example.label-with-value=&quot;foo&quot; LABEL version=&quot;1.0&quot; LABEL description=&quot;This text illustrates that label-values can span multiple lines.&quot; 但是并不建议这样写，最好就写成一行，如太长需要换行的话则使用\\符号 如下： LABEL multi.label1=&quot;value1&quot; \\ multi.label2=&quot;value2&quot; \\ other=&quot;value3&quot; 说明：LABEL会继承基础镜像种的LABEL，如遇到key相同，则值覆盖 MAINTAINER 指定作者 语法： MAINTAINER &lt;name&gt; EXPOSE 暴漏容器运行时的监听端口给外部 EXPOSE并不会使容器访问主机的端口 如果想使得容器与主机的端口有映射关系，必须在容器启动的时候加上 -P参数 ENV 功能为设置环境变量 语法有两种 1. ENV &lt;key&gt; &lt;value&gt; 2. ENV &lt;key&gt;=&lt;value&gt; ... 两者的区别就是第一种是一次设置一个，第二种是一次设置多个 ADD 复制命令 tar包会自动解压 如果把虚拟机与容器想象成两台linux服务器的话，那么这个命令就类似于scp，只是scp需要加用户名和密码的权限验证，而ADD不用。 语法如下： 1. ADD &lt;src&gt;... &lt;dest&gt; 2. ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] 路径的填写可以是容器内的绝对路径，也可以是相对于工作目录的相对路径 可以是一个本地文件或者是一个本地压缩文件，还可以是一个url 如果把写成一个url，那么ADD就类似于wget命令 如以下写法都是可以的： ADD test relativeDir/ ADD test /relativeDir ADD http://example.com/foobar / 尽量不要把写成一个文件夹，如果是一个文件夹了，复制整个目录的内容,包括文件系统元数据 COPY 复制命令 语法如下： 1. COPY &lt;src&gt;... &lt;dest&gt; 2. COPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] COPY与ADD的区别 COPY的只能是本地文件，其他用法一致 ENTRYPOINT 启动时的默认命令 语法如下： 1. ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] 2. ENTRYPOINT command param1 param2 如果从上到下看到这里的话，那么你应该对这两种语法很熟悉啦。 第二种就是写shell 第一种就是可执行文件加参数 与CMD比较说明（这俩命令太像了，而且还可以配合使用）： 1. 相同点： 只能写一条，如果写了多条，那么只有最后一条生效 容器启动时才运行，运行时机相同 2. 不同点： ENTRYPOINT不会被运行的command覆盖，而CMD则会被覆盖 如果我们在Dockerfile种同时写了ENTRYPOINT和CMD，并且CMD指令不是一个完整的可执行命令，那么CMD指定的内容将会作为ENTRYPOINT的参数 如下： FROM ubuntu ENTRYPOINT [&quot;top&quot;, &quot;-b&quot;] CMD [&quot;-c&quot;] 如果我们在Dockerfile种同时写了ENTRYPOINT和CMD，并且CMD是一个完整的指令，那么它们两个会互相覆盖，谁在最后谁生效 VOLUME 可实现挂载功能，可以将内地文件夹或者其他容器种得文件夹挂在到这个容器种 语法为： VOLUME [&quot;/data&quot;] 说明： [&quot;/data&quot;]可以是一个JsonArray ，也可以是多个值。所以如下几种写法都是正确的 VOLUME [\\&quot;/var/log/\\&quot;] VOLUME /var/log VOLUME /var/log /var/db 一般的使用场景为需要持久化存储数据时 容器使用的是AUFS，这种文件系统不能持久化数据，当容器关闭后，所有的更改都会丢失。 所以当数据需要持久化时用这个命令。 USER 设置启动容器的用户，可以是用户名或UID，所以，只有下面的两种写法是正确的 USER daemo USER UID 注意：如果设置了容器以daemon用户去运行，那么RUN, CMD 和 ENTRYPOINT 都会以这个用户去运行 WORKDIR 设置工作目录 语法： WORKDIR /path/to/workdir 设置工作目录，对RUN,CMD,ENTRYPOINT,COPY,ADD生效。如果不存在则会创建，也可以设置多次。 如： WORKDIR /a WORKDIR b WORKDIR c RUN pwd pwd执行的结果是/a/b/c WORKDIR也可以解析环境变量 如： ENV DIRPATH /path WORKDIR $DIRPATH/$DIRNAME RUN pwd pwd的执行结果是/path/$DIRNAME ARG 设置变量 语法： ARG &lt;name&gt;[=&lt;default value&gt;] 设置变量命令，ARG命令定义了一个变量，在docker build创建镜像的时候，使用 --build-arg =来指定参数 如果用户在build镜像时指定了一个参数没有定义在Dockerfile种，那么将有一个Warning 提示如下： [Warning] One or more build-args [foo] were not consumed. 我们可以定义一个或多个参数，如下： FROM busybox ARG user1 ARG buildno ... 也可以给参数一个默认值： FROM busybox ARG user1=someuser ARG buildno=1 ... 如果我们给了ARG定义的参数默认值，那么当build镜像时没有指定参数值，将会使用这个默认值 ONBUILD 语法： ONBUILD [INSTRUCTION] 这个命令只对当前镜像的子镜像生效。 比如当前镜像为A，在Dockerfile种添加： ONBUILD RUN ls -al 这个 ls -al 命令不会在A镜像构建或启动的时候执行 此时有一个镜像B是基于A镜像构建的，那么这个ls -al 命令会在B镜像构建的时候被执行。 STOPSIGNAL STOPSIGNAL命令是的作用是当容器推出时给系统发送什么样的指令 语法： STOPSIGNAL signal HEALTHCHECK 容器健康状况检查命令 语法有两种： 1. HEALTHCHECK [OPTIONS] CMD command 2. HEALTHCHECK NONE 第一个的功能是在容器内部运行一个命令来检查容器的健康状况 第二个的功能是在基础镜像中取消健康检查命令 [OPTIONS]的选项支持以下三中选项： --interval=DURATION 两次检查默认的时间间隔为30秒 --timeout=DURATION 健康检查命令运行超时时长，默认30秒 --retries=N 当连续失败指定次数后，则容器被认为是不健康的，状态为unhealthy，默认次数是3 注意： HEALTHCHECK命令只能出现一次，如果出现了多次，只有最后一个生效。 CMD后边的命令的返回值决定了本次健康检查是否成功，具体的返回值如下： 0: success - 表示容器是健康的 1: unhealthy - 表示容器已经不能工作了 2: reserved - 保留值 例子： HEALTHCHECK --interval=5m --timeout=3s \\ CMD curl -f http://localhost/ || exit 1 健康检查命令是：curl -f http://localhost/ || exit 1 两次检查的间隔时间是5秒 命令超时时间为3秒 ","link":"https://maodou38.github.io/dockerfile-code/"},{"title":"Docker常用命令","content":"查看 Docker 版本 docker version 从 Docker 文件构建 Docker 映像 docker build -t image-name docker-file-location 运行 Docker 映像 docker run -d image-name 查看可用的 Docker 映像 docker images 查看最近的运行容器 docker ps -l 查看所有正在运行的容器 docker ps -a 停止运行容器 docker stop container_id 删除一个镜像 docker rmi image-name 删除所有镜像 docker rmi $(docker images -q) 强制删除所有镜像 docker rmi -r $(docker images -q) 删除所有虚悬镜像 docker rmi $(docker images -q -f dangling=true) 删除所有未运行容器 sudo docker container prune 删除所有容器 docker rm $(docker ps -a -q) 进入 Docker 容器 docker exec -it container-id /bin/bash 查看所有数据卷 docker volume ls 删除指定数据卷 docker volume rm [volume_name] 删除所有未关联的数据卷 docker volume rm $(docker volume ls -qf dangling=true) 从主机复制文件到容器 sudo docker cp host_path containerID:container_path 从容器复制文件到主机 sudo docker cp containerID:container_path host_path ","link":"https://maodou38.github.io/docker-code/"},{"title":"基于 Docker 安装 GitLab Runner及使用","content":"基于 Docker 安装 GitLab Runner 环境准备 创建工作目录 /usr/local/docker/runner 创建构建目录 /usr/local/docker/runner/environment 下载 jdk-8u152-linux-x64.tar.gz 并复制到 /usr/local/docker/runner/environment 下载 apache-maven-3.5.3-bin.tar.gz 并复制到 /usr/local/docker/runner/environment daemon.json 在 /usr/local/docker/runner/environment 目录下创建 daemon.json，用于配置加速器和仓库地址 { &quot;registry-mirrors&quot;: [ &quot;https://registry.docker-cn.com&quot; ], &quot;insecure-registries&quot;: [ &quot;192.168.10.133:5000&quot; ] } Dockerfile 在 /usr/local/docker/runner/environment 目录下创建 Dockerfile FROM gitlab/gitlab-runner MAINTAINER maodou38 &lt;maodoulove19950815@vip.qq.com&gt; # 修改软件源 RUN echo 'deb http://mirrors.aliyun.com/ubuntu/ xenial main restricted universe multiverse' &gt; /etc/apt/sources.list &amp;&amp; \\ echo 'deb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted universe multiverse' &gt;&gt; /etc/apt/sources.list &amp;&amp; \\ echo 'deb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted universe multiverse' &gt;&gt; /etc/apt/sources.list &amp;&amp; \\ echo 'deb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse' &gt;&gt; /etc/apt/sources.list &amp;&amp; \\ apt-get update -y &amp;&amp; \\ apt-get clean # 安装 Docker RUN apt-get -y install apt-transport-https ca-certificates curl software-properties-common &amp;&amp; \\ curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | apt-key add - &amp;&amp; \\ add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot; &amp;&amp; \\ apt-get update -y &amp;&amp; \\ apt-get install -y docker-ce COPY daemon.json /etc/docker/daemon.json # 安装 Docker Compose WORKDIR /usr/local/bin RUN wget https://raw.githubusercontent.com/topsale/resources/master/docker/docker-compose RUN chmod +x docker-compose # 安装 Java RUN mkdir -p /usr/local/java WORKDIR /usr/local/java COPY jdk-8u152-linux-x64.tar.gz /usr/local/java RUN tar -zxvf jdk-8u152-linux-x64.tar.gz &amp;&amp; \\ rm -fr jdk-8u152-linux-x64.tar.gz # 安装 Maven RUN mkdir -p /usr/local/maven WORKDIR /usr/local/maven # RUN wget https://raw.githubusercontent.com/topsale/resources/master/maven/apache-maven-3.5.3-bin.tar.gz COPY apache-maven-3.5.3-bin.tar.gz /usr/local/maven RUN tar -zxvf apache-maven-3.5.3-bin.tar.gz &amp;&amp; \\ rm -fr apache-maven-3.5.3-bin.tar.gz # COPY settings.xml /usr/local/maven/apache-maven-3.5.3/conf/settings.xml # 配置环境变量 ENV JAVA_HOME /usr/local/java/jdk1.8.0_152 ENV MAVEN_HOME /usr/local/maven/apache-maven-3.5.3 ENV PATH $PATH:$JAVA_HOME/bin:$MAVEN_HOME/bin WORKDIR / docker-compose.yml 在 /usr/local/docker/runner 目录下创建 docker-compose.yml version: '3.1' services: gitlab-runner: build: environment restart: always container_name: gitlab-runner privileged: true volumes: - ./config:/etc/gitlab-runner - /var/run/docker.sock:/var/run/docker.sock 注册 Runner docker exec -it gitlab-runner gitlab-runner register # 输入 GitLab 地址 Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/): http://192.168.10.132/ # 输入 GitLab Token Please enter the gitlab-ci token for this runner: 1Lxq_f1NRfCfeNbE5WRh # 输入 Runner 的说明 Please enter the gitlab-ci description for this runner: 可以为空 # 设置 Tag，可以用于指定在构建规定的 tag 时触发 ci Please enter the gitlab-ci tags for this runner (comma separated): deploy # 这里选择 true ，可以用于代码上传后直接执行 Whether to run untagged builds [true/false]: true # 这里选择 false，可以直接回车，默认为 false Whether to lock Runner to current project [true/false]: false # 选择 runner 执行器，这里我们选择的是 shell Please enter the executor: virtualbox, docker+machine, parallels, shell, ssh, docker-ssh+machine, kubernetes, docker, docker-ssh: shell 使用 Runner GitLab CI 地址与令牌参数 项目 –&gt; 设置 –&gt; CI/CD –&gt; Runner 设置 .gitlab-ci.yml 在项目工程下编写 .gitlab-ci.yml 配置文件： stages: - install_deps - test - build - deploy_test - deploy_production cache: key: ${CI_BUILD_REF_NAME} paths: - node_modules/ - dist/ # 安装依赖 install_deps: stage: install_deps only: - develop - master script: - npm install # 运行测试用例 test: stage: test only: - develop - master script: - npm run test # 编译 build: stage: build only: - develop - master script: - npm run clean - npm run build:client - npm run build:server # 部署测试服务器 deploy_test: stage: deploy_test only: - develop script: - pm2 delete app || true - pm2 start app.js --name app # 部署生产服务器 deploy_production: stage: deploy_production only: - master script: - bash scripts/deploy/deploy.sh 上面的配置把一次 Pipeline 分成五个阶段： 安装依赖(install_deps) 运行测试(test) 编译(build) 部署测试服务器(deploy_test) 部署生产服务器(deploy_production) 注意： 设置 Job.only 后，只有当 develop 分支和 master 分支有提交的时候才会触发相关的 Jobs。 节点说明： stages：定义构建阶段，这里只有一个阶段 deploy deploy：构建阶段 deploy 的详细配置也就是任务配置 script：需要执行的 shell 脚本 only：这里的 master 指在提交到 master 时执行 tags：与注册 runner 时的 tag 匹配 其它命令 删除注册信息 gitlab-ci-multi-runner unregister --name &quot;名称&quot; 查看注册列表 gitlab-ci-multi-runner list Dockerfile示例 FROM openjdk:8-jre MAINTAINER maodou38 &lt;maodoulove19950815@vip.qq.com&gt; ENV APP_VERSION 1.0.0-SNAPSHOT ENV DOCKERIZE_VERSION v0.6.1 RUN wget https://github.com/jwilder/dockerize/releases/download/$DOCKERIZE_VERSION/dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz \\ &amp;&amp; tar -C /usr/local/bin -xzvf dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz \\ &amp;&amp; rm dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz RUN mkdir /app COPY myshop-service-user-provider-$APP_VERSION.jar /app/app.jar ENTRYPOINT [&quot;dockerize&quot;, &quot;-timeout&quot;, &quot;5m&quot;, &quot;-wait&quot;, &quot;tcp://192.168.10.131:3306&quot;, &quot;java&quot;, &quot;-Djava.security.egd=file:/dev/./urandom&quot;, &quot;-jar&quot;, &quot;/app/app.jar&quot;] EXPOSE 8501 DOCKERIZE是一个监听插件，监听依赖服务是否启动 ","link":"https://maodou38.github.io/gitlab-runner/"},{"title":"安装docker及docker-compose","content":"Docker安装（centos） 1.删除已安装的Docker sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 2.配置阿里云Docker Yum源 sudo yum install -y yum-utils device-mapper-persistent-data lvm2 sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 3.安装指定版本 yum list docker-ce --showduplicates 3.1、安装较旧版本 //注意：需要指定完整的rpm包的包名，并且加上--setopt=obsoletes=0 参数： yum install -y --setopt=obsoletes=0 \\ docker-ce-17.03.2.ce-1.el7.centos.x86_64 \\ docker-ce-selinux-17.03.2.ce-1.el7.centos.noarch 3.2、安装Docker最新版本 sudo yum install docker-ce 4.启用阿里云Docker镜像加速 https://cr.console.aliyun.com 自己申请账号，下面是我自己的 sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF' { &quot;registry-mirrors&quot;: [&quot;https://a0cmmvhl.mirror.aliyuncs.com&quot;] } EOF 5.启动Docker服务 systemctl enable docker systemctl start docker docker安装(debian) 1.卸载旧版本 sudo apt-get remove docker docker-engine docker.io containerd runc 2.使用 Docker 仓库进行安装 #设置仓库 #更新 apt 包索引 sudo apt-get update #安装 apt 依赖包，用于通过 HTTPS 来获取仓库 sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg2 \\ software-properties-common #添加 Docker 的官方 GPG 密钥 curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add - # 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 通过搜索指纹的后8个字符，验证您现在是否拥有带有指纹的密钥 sudo apt-key fingerprint 0EBFCD88 #使用以下指令设置稳定版仓库 sudo add-apt-repository \\ &quot;deb [arch=amd64] https://download.docker.com/linux/debian \\ $(lsb_release -cs) \\ stable&quot; 3.安装 Docker Engine-Community #更新 apt 包索引 sudo apt-get update #安装最新版本的 Docker Engine-Community 和 containerd ，或者转到下一步安装特定版本： sudo apt-get install docker-ce docker-ce-cli containerd.io #要安装特定版本的 Docker Engine-Community，请在仓库中列出可用版本，然后选择一种安装。列出您的仓库中可用的版本： apt-cache madison docker-ce Docker 用户组设置 1.创建docker用户组（正常来说docker安装后会自动有docker用户组） sudo groupadd docker 2.两步选一步 2.1将当前用户添加进组 sudo gpasswd -a ${USER} docker 2.2添加指定用户进组 sudo usermod -aG docker ${用户名} 3.重启docker sudo systemctl restart docker Docker-compose安装(建议使用方法一) 方法一：源码安装 #自己在https://github.com/docker/compose/releases查看版本替换下面链接的版本号 curl -L https://github.com/docker/compose/releases/download/1.24.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose #验证 docker-compose --version 方法二：pip安装 ###安装python-pip yum -y install epel-release yum -y install python-pip #若后续安装docker-compose失败，使用 yum -y install python3-pip pip install --upgrade pip 安装docker-compose #若安装的是python-pip3,则此处命令为pip3 install docker-compose pip install docker-compose #验证 docker-compose version ","link":"https://maodou38.github.io/docker-install/"}]}